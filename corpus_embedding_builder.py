# -*- coding: utf-8 -*-
"""
QGpT: Improving Table Retrieval with Question Generation from Partial Tables
Corpus Embedding Builder

This script builds vector embeddings for table corpora using the QGpT framework.
It processes table data from JSON files and creates vector databases with corpus-specific naming.

Usage:
    python corpus_embedding_builder.py [corpus_file_path]
    python corpus_embedding_builder.py --list  # åˆ—å‡ºæ‰€æœ‰å¯ç”¨èªæ–™åº«
    python corpus_embedding_builder.py --all   # å»ºç«‹æ‰€æœ‰èªæ–™åº«çš„ embedding

Author: QGpT Research Team
Repository: https://github.com/UDICatNCHU/QGpT
"""

import argparse
import sys
from pathlib import Path
from typing import List, Dict, Optional
from pymilvus import MilvusClient
from FlagEmbedding import BGEM3FlagModel

from utils import (
    load_json_dataset, 
    preprocess_text, 
    extract_corpus_name_from_path,
    generate_db_name,
    generate_collection_name,
    get_corpus_files,
    validate_corpus_structure
)


class CorpusEmbeddingBuilder:
    """èªæ–™åº«åµŒå…¥å‘é‡å»ºç«‹å™¨"""
    
    def __init__(self, embedding_dim=1024):
        """
        åˆå§‹åŒ–å»ºç«‹å™¨
        
        Args:
            embedding_dim: åµŒå…¥å‘é‡ç¶­åº¦ (BGE-M3 è¼¸å‡º 1024 ç¶­)
        """
        self.embedding_dim = embedding_dim
        print("ğŸ”„ åˆå§‹åŒ– BGE-M3 æ¨¡å‹...")
        self.embedding_fn = BGEM3FlagModel("BAAI/bge-m3", use_fp16=True)
        print("âœ… BGE-M3 æ¨¡å‹è¼‰å…¥å®Œæˆ")
        
    def build_embeddings(self, corpus_path, force_rebuild=False):
        """
        ç‚ºæŒ‡å®šèªæ–™åº«å»ºç«‹åµŒå…¥å‘é‡
        
        Args:
            corpus_path: èªæ–™åº«æª”æ¡ˆè·¯å¾‘
            force_rebuild: æ˜¯å¦å¼·åˆ¶é‡å»ºï¼ˆå³ä½¿è³‡æ–™åº«å·²å­˜åœ¨ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸå»ºç«‹
        """
        try:
            # æå–èªæ–™åº«åç¨±å’Œç”Ÿæˆè³‡æ–™åº«åç¨±
            corpus_name = extract_corpus_name_from_path(corpus_path)
            db_name = generate_db_name(corpus_name)
            collection_name = generate_collection_name(corpus_name)
            
            print(f"ğŸ”„ è™•ç†èªæ–™åº«: {corpus_name}")
            print(f"   æª”æ¡ˆè·¯å¾‘: {corpus_path}")
            print(f"   è³‡æ–™åº«åç¨±: {db_name}")
            print(f"   é›†åˆåç¨±: {collection_name}")
            
            # æª¢æŸ¥è³‡æ–™åº«æ˜¯å¦å·²å­˜åœ¨
            if Path(db_name).exists() and not force_rebuild:
                print(f"â„¹ï¸  è³‡æ–™åº« '{db_name}' å·²å­˜åœ¨ï¼Œè·³éå»ºç«‹ï¼ˆä½¿ç”¨ --force å¼·åˆ¶é‡å»ºï¼‰")
                return True
            
            # è¼‰å…¥èªæ–™åº«è³‡æ–™
            print("ğŸ”„ è¼‰å…¥èªæ–™åº«è³‡æ–™...")
            data = load_json_dataset(corpus_path)
            
            if not validate_corpus_structure(data):
                print(f"âŒ èªæ–™åº«çµæ§‹é©—è­‰å¤±æ•—: {corpus_path}")
                return False
            
            print(f"âœ… è¼‰å…¥äº† {len(data)} å€‹è¡¨æ ¼æ–‡ä»¶")
            
            # å»ºç«‹ Milvus å‘é‡è³‡æ–™åº«å®¢æˆ¶ç«¯
            print("ğŸ”„ åˆå§‹åŒ–å‘é‡è³‡æ–™åº«...")
            client = MilvusClient(db_name)
            
            # åˆªé™¤ç¾æœ‰é›†åˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰ä¸¦å»ºç«‹æ–°é›†åˆ
            if client.has_collection(collection_name=collection_name):
                client.drop_collection(collection_name=collection_name)
                print("ğŸ—‘ï¸  å·²åˆªé™¤ç¾æœ‰é›†åˆ")
            
            # å»ºç«‹æ–°çš„å‘é‡é›†åˆ
            client.create_collection(
                collection_name=collection_name,
                dimension=self.embedding_dim,
            )
            print("âœ… å»ºç«‹æ–°çš„å‘é‡é›†åˆ")
            
            # æº–å‚™æ–‡ä»¶è³‡æ–™
            print("ğŸ”„ é è™•ç†æ–‡ä»¶...")
            documents = []
            metadata = []
            
            for item in data:
                # é è™•ç†æ–‡å­—
                clean_text = preprocess_text(item['Text'])
                documents.append(clean_text)
                
                # ä¿å­˜å…ƒè³‡æ–™
                metadata.append({
                    'id': item['id'],
                    'filename': item.get('FileName', ''),
                    'sheet_name': item.get('SheetName', '')
                })
            
            # ç”ŸæˆåµŒå…¥å‘é‡
            print("ğŸ”„ ç”ŸæˆåµŒå…¥å‘é‡...")
            vectors = self.embedding_fn.encode(documents)['dense_vecs']  # BGE-M3 ä½¿ç”¨ encode æ–¹æ³•
            print(f"å‘é‡ç¶­åº¦: {len(vectors[0])}, å‘é‡æ•¸é‡: {len(vectors)}")
            
            # æº–å‚™æ’å…¥è³‡æ–™
            print("ğŸ”„ æº–å‚™æ’å…¥è³‡æ–™...")
            insert_data = []
            for i, (doc, vec, meta) in enumerate(zip(documents, vectors, metadata)):
                insert_data.append({
                    "id": i,
                    "vector": vec.astype('float32').tolist(),  # è½‰æ›ç‚º float32 ä¸¦è½‰ç‚º list
                    "text": doc,  # é™åˆ¶æ–‡å­—é•·åº¦ä»¥ç¯€çœç©ºé–“
                    "original_id": meta['id'],
                    "filename": meta['filename'],
                    "sheet_name": meta['sheet_name']
                })
            
            # æ’å…¥è³‡æ–™åˆ° Milvus
            print("ğŸ”„ æ’å…¥è³‡æ–™åˆ°å‘é‡è³‡æ–™åº«...")
            client.insert(collection_name=collection_name, data=insert_data)
            
            print(f"âœ… æˆåŠŸå»ºç«‹èªæ–™åº« '{corpus_name}' çš„åµŒå…¥å‘é‡")
            print(f"   è³‡æ–™åº«æª”æ¡ˆ: {db_name}")
            print(f"   è¨˜éŒ„æ•¸é‡: {len(insert_data)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ å»ºç«‹åµŒå…¥å‘é‡å¤±æ•—: {e}")
            return False
    
    def build_all_embeddings(self, force_rebuild=False):
        """
        ç‚ºæ‰€æœ‰å¯ç”¨èªæ–™åº«å»ºç«‹åµŒå…¥å‘é‡
        
        Args:
            force_rebuild: æ˜¯å¦å¼·åˆ¶é‡å»º
            
        Returns:
            å»ºç«‹çµæœå­—å…¸ {corpus_name: success}
        """
        corpus_files = get_corpus_files()
        results = {}
        
        if not corpus_files:
            print("âš ï¸  æ²’æœ‰æ‰¾åˆ°ä»»ä½•èªæ–™åº«æª”æ¡ˆ")
            return results
        
        print(f"ğŸ”„ æ‰¾åˆ° {len(corpus_files)} å€‹èªæ–™åº«æª”æ¡ˆ")
        
        for i, corpus_info in enumerate(corpus_files, 1):
            print(f"\n{'='*60}")
            print(f"è™•ç†èªæ–™åº« {i}/{len(corpus_files)}")
            success = self.build_embeddings(corpus_info['path'], force_rebuild)
            results[corpus_info['name']] = success
        
        # é¡¯ç¤ºç¸½çµ
        print(f"\n{'='*60}")
        print("å»ºç«‹å®Œæˆç¸½çµ:")
        successful = sum(1 for success in results.values() if success)
        print(f"æˆåŠŸ: {successful}/{len(results)}")
        
        for corpus_name, success in results.items():
            status = "âœ…" if success else "âŒ"
            print(f"  {status} {corpus_name}")
        
        return results


def main():
    """ä¸»ç¨‹å¼"""
    parser = argparse.ArgumentParser(
        description='QGpT èªæ–™åº«åµŒå…¥å‘é‡å»ºç«‹å™¨',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  # ç‚ºæŒ‡å®šèªæ–™åº«å»ºç«‹åµŒå…¥å‘é‡
  python corpus_embedding_builder.py Corpora/Table1_mimo_table_length_variation/mimo_ch/1k_token.json
  
  # åˆ—å‡ºæ‰€æœ‰å¯ç”¨èªæ–™åº«
  python corpus_embedding_builder.py --list
  
  # ç‚ºæ‰€æœ‰èªæ–™åº«å»ºç«‹åµŒå…¥å‘é‡
  python corpus_embedding_builder.py --all
  
  # å¼·åˆ¶é‡å»ºå·²å­˜åœ¨çš„è³‡æ–™åº«
  python corpus_embedding_builder.py --all --force
        """
    )
    
    parser.add_argument('corpus_path', nargs='?', help='èªæ–™åº«æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--list', action='store_true', help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨èªæ–™åº«')
    parser.add_argument('--all', action='store_true', help='ç‚ºæ‰€æœ‰èªæ–™åº«å»ºç«‹åµŒå…¥å‘é‡')
    parser.add_argument('--force', action='store_true', help='å¼·åˆ¶é‡å»ºå·²å­˜åœ¨çš„è³‡æ–™åº«')
    parser.add_argument('--dim', type=int, default=1024, help='åµŒå…¥å‘é‡ç¶­åº¦ (é è¨­: 1024)')
    
    args = parser.parse_args()
    
    # åˆ—å‡ºæ‰€æœ‰å¯ç”¨èªæ–™åº«
    if args.list:
        corpus_files = get_corpus_files()
        if not corpus_files:
            print("æ²’æœ‰æ‰¾åˆ°ä»»ä½•èªæ–™åº«æª”æ¡ˆ")
            return
        
        print("å¯ç”¨çš„èªæ–™åº«æª”æ¡ˆ:")
        print("=" * 80)
        for i, corpus_info in enumerate(corpus_files, 1):
            print(f"{i:2d}. åç¨±: {corpus_info['name']}")
            print(f"     è·¯å¾‘: {corpus_info['path']}")
            print(f"     è³‡æ–™åº«: {corpus_info['db_name']}")
            print(f"     é›†åˆ: {corpus_info['collection_name']}")
            print()
        return
    
    # åˆå§‹åŒ–å»ºç«‹å™¨
    builder = CorpusEmbeddingBuilder(embedding_dim=args.dim)
    
    # ç‚ºæ‰€æœ‰èªæ–™åº«å»ºç«‹åµŒå…¥å‘é‡
    if args.all:
        builder.build_all_embeddings(force_rebuild=args.force)
        return
    
    # ç‚ºæŒ‡å®šèªæ–™åº«å»ºç«‹åµŒå…¥å‘é‡
    if args.corpus_path:
        if not Path(args.corpus_path).exists():
            print(f"âŒ æ‰¾ä¸åˆ°æª”æ¡ˆ: {args.corpus_path}")
            sys.exit(1)
        
        success = builder.build_embeddings(args.corpus_path, force_rebuild=args.force)
        sys.exit(0 if success else 1)
    
    # å¦‚æœæ²’æœ‰æä¾›åƒæ•¸ï¼Œé¡¯ç¤ºå¹«åŠ©
    parser.print_help()


if __name__ == "__main__":
    main()
